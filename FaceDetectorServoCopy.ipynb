{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee52ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiy.vision.inference import CameraInference\n",
    "from aiy.vision.models import object_detection\n",
    "from aiy.vision.streaming.server import StreamingServer\n",
    "from aiy.vision.streaming import svg\n",
    "from aiy.leds import Leds, Color\n",
    "from gpiozero import Servo\n",
    "from aiy.pins import PIN_A\n",
    "\n",
    "from picamera import PiCamera\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "import contextlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269c4f0",
   "metadata": {},
   "source": [
    "### Animal Species Detector\n",
    "This should be fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5f4fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/gpiozero/output_devices.py:1533: PWMSoftwareFallback: To reduce servo jitter, use the pigpio pin factory.See https://gpiozero.readthedocs.io/en/stable/api_output.html#servo for more info\n",
      "  'To reduce servo jitter, use the pigpio pin factory.'\n"
     ]
    }
   ],
   "source": [
    "servo = Servo(PIN_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67328dc",
   "metadata": {},
   "source": [
    "I added some code here that is called to create the overlay - basically the box around the face and the score above. You can customize it and/or add information you want to overlay on the camera feed. **This is not needed for the servo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a383051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svg_overlay(objects, frame_size):\n",
    "\n",
    "    #JOY_COLOR = (255, 70, 0)\n",
    "    #SAD_COLOR = (0, 0, 64)\n",
    "\n",
    "    labels = [\"None\", \"Person\", \"Cat\", \"Dog\"]\n",
    "    width, height = frame_size\n",
    "    doc = svg.Svg(width=width, height=height)\n",
    "\n",
    "    for obj in objects:\n",
    "        x, y, w, h = obj.bounding_box\n",
    "        doc.add(svg.Rect(x=int(x), y=int(y), width=int(w), height=int(h), rx=10, ry=10,\n",
    "                         fill_opacity=0.3,\n",
    "                         style='stroke:white;stroke-width:4px'))\n",
    "\n",
    "        doc.add(svg.Text(labels[obj.kind], x=x, y=y-10, fill='white', font_size=30))\n",
    "\n",
    "    return str(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de67ca5",
   "metadata": {},
   "source": [
    "#### Main loop\n",
    "\n",
    "Here is our main loop based on the code we used last time. Look at the comments on what was changed. Basically we removed the part saving the picture and adjust the servo value to the joy score each frame. We also added the streaming back in, to while this cell runs, you can connect to http://orcspi-vis.local:4664 and see the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01f89e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects:  kind=CAT(2), score=0.645232, bbox=(248, 313, 591, 914)\n",
      "Interrupted ..\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "with contextlib.ExitStack() as stack:\n",
    "    leds   = stack.enter_context(Leds())\n",
    "    camera = stack.enter_context(PiCamera(sensor_mode=4, resolution=(820, 616)))\n",
    "\n",
    "    # This starts and runs the streaming of the camera\n",
    "    server = stack.enter_context(StreamingServer(camera))  \n",
    "\n",
    "    print (\"Loading model - hold on ..\")\n",
    "    \n",
    "    # Move the servo to low (-1)\n",
    "    servo.min()\n",
    "    \n",
    "    # Do inference on VisionBonnet\n",
    "    with CameraInference(object_detection.model()) as inference:\n",
    "        try:   \n",
    "            for result in inference.run():\n",
    "                leds.update(Leds.rgb_on(Color.BLACK))\n",
    "                objects = object_detection.get_objects(result)\n",
    "                \n",
    "                # This sends the overlay (boxes) to add to the camera stream\n",
    "                server.send_overlay(svg_overlay(objects, (result.width, result.height)))\n",
    "\n",
    "                if len(objects) >= 1:\n",
    "                    clear_output(wait=True)                 \n",
    "                    leds.update(Leds.rgb_on(Color.PURPLE))\n",
    "                    print(\"Objects: \", objects[0]) \n",
    "                    \n",
    "                    # This sets the servo to the joy score value\n",
    "                    # To use the full range (-1 to 1) we multiply the score by 2 and subtract 1\n",
    "                    #servo.value = 2*faces[0].joy_score  - 1\n",
    "                                           \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted ..\")\n",
    "            \n",
    "    leds.update(Leds.rgb_off())\n",
    "    \n",
    "    # Servo back to the middle upon ending\n",
    "    servo.mid()\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1edd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
